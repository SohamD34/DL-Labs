{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential, ReLU, Module, Dropout, Sigmoid, Linear, BatchNorm2d\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary parameters\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "batch_size = 512\n",
    "epochs = 20\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42   # for reproducibility\n",
    "torch.manual_seed(seed)     # set seed for torch\n",
    "torch.backends.cudnn.benchmark = False \n",
    "torch.backends.cudnn.deterministic = True \n",
    "batch_size = 512\n",
    "epochs = 20 \n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train, val & test loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn = datasets.SVHN(root='E:/torchvision/datasets', download=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_data, test_data = train_test_split(svhn, train_size=0.8, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.125, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "51279\n",
      "torch.Size([512, 3, 32, 32])\n",
      "torch.Size([512])\n",
      "\n",
      "Validation data\n",
      "7326\n",
      "torch.Size([512, 3, 32, 32])\n",
      "torch.Size([512])\n",
      "\n",
      "Test data\n",
      "14652\n",
      "torch.Size([512, 3, 32, 32])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the input \n",
    "\n",
    "print(\"Train data\")\n",
    "print(len(train_data))\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break\n",
    "\n",
    "print(\"\\nValidation data\")\n",
    "print(len(val_data))\n",
    "for batch in val_loader:\n",
    "    images, labels = batch\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break\n",
    "\n",
    "print(\"\\nTest data\")\n",
    "print(len(test_data))\n",
    "for batch in test_loader:\n",
    "    images, labels = batch\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnderCompleteAutoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(UnderCompleteAutoencoder, self).__init__()\n",
    "\n",
    "        self.input_dim = 3*32*32\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, int(self.input_dim*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(self.input_dim*0.5), int(self.input_dim*0.25)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(int(self.input_dim*0.25), int(self.input_dim*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(self.input_dim*0.5), self.input_dim),\n",
    "            nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnderCompleteAutoencoder().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training undercomplete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, _ in train_loader:\n",
    "\n",
    "        images = images.view(512, -1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        train_loss = criterion(outputs, images)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += train_loss.item()\n",
    "\n",
    "    loss = running_loss/len(train_loader)\n",
    "\n",
    "    print(\"Epoch : \",epoch+1,\"/\",epochs,\"recon loss = \",loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
